# AI 与 AI 安全的一些基本概念

## 1. 机器学习/深度学习/强化学习的基本概念及关系：

#### (1) 机器学习：通过机器学习过程的具有无确定规则的定义功能的程序

#### (2) 神经网络：在机器学习的算法基础上添加模拟人类神经网络的结构

#### (3) 强化学习：通过程序与外部环境的反馈做到基于反馈优化计算的功能

## 2. 监督学习与无监督学习的基本概念：

#### (1) 监督学习：数据集有标签，多用于分类、回归问题，如图像识别、垃圾邮件分类等

#### (2) 无监督学习：数据集不带标签，多用于聚类、数据降维等，如预训练、入侵检测等

## 3. 敌手模型：

**攻击者称为敌手，敌手模型可以从敌手目标、敌手知识、敌手能力、敌手策略 4 个维度刻画**

#### (1) 敌手目标：分为破坏机器学习的机密性、完整性、可用性

- 机密性：包含用户隐私的敏感信息不被泄露

- 完整性：敌手诱导模型行为或者使模型在预测中输出指定分类标签

- 可用性：阻止用户获得模型正确的输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖

#### (2) 敌手知识：包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等

#### (3) 敌手能力：指敌手在具有一定知识背景下，对模型或者训练数据、测试数据的控制能力

#### (4) 敌手策略：指敌手为达到攻击目标，根据自身的知识和能力，采取的具体攻击方式，如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等

## 4、机器学习的安全威胁以及安全性防御技术

### 训练阶段

- 投毒攻击：敌手对训练数据进行修改、删除或注入精心制作的恶意数据，改变训练数据原有的分布，使学习算法在逻辑上发生改变进而威胁目标模型。当模型预测误差小于$\epsilon$时，其最大容忍修改训练数据集的概率是 b，b 应满足$b\leq\frac{\epsilon}{\epsilon+1}$

### 预测阶段

- 对抗攻击：敌手精心制造使模型错分类的样本称为对抗样本，此阶段的攻击分为黑盒攻击和白盒攻击
- 询问攻击：通过观察特定的输入对应的输出信息，建立与目标模型相似的模型进行攻击

### 机器学习的安全性防御技术

- 正则化：通过为代价函数添加正则项（也叫惩罚项）提高目标模型的泛化能力，在预测中遇见未知数据集具有良好的适应性抵抗攻击

- 对抗训练：在训练数据集中引入对抗样本，通过合法化的对抗样本对目标模型的训练提供模型的顽健性 (由于在对抗训练中引入所有未知攻击的对抗样本是不现实的，对抗样本的非适应性导致对抗训练的局限性)

- 防御精馏：防御者与敌手之间的博弈可表示为：敌手最小化制造样本的成本，防御者最小化存在对抗样本的代价函数。防御者与敌手不断交互博弈的过程增加目标模型的顽健性

## 5、机器学习的隐私威胁及隐私保护技术

### 训练阶段

- 窃取训练数据：机器学习训练方式分为集中式和联合分布式

### 预测阶段

- 逆向攻击：可以提取训练数据(部分或全部)或训练数据的统计特征

- 成员推理攻击：给定一条记录可以判定是否在训练数据集中

### 机器学习隐私保护技术

- 同态加密技术：允许用户直接在密文上做运算，得到的结果解密后与在明文下运算结果一致，是最直接有效保护用户隐私的一项技术

- 差分隐私技术：通过引入噪声使至多相差 1 个数据的 2 个数据集查询结果概率不可分

- 安全多方计算(MPC)
